{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPG Examples\n",
    "This document shows how to use the PyTPG API. We make use of OpenAI Gym to run examples, and we assume you already have PyTPG installed, see the readme for installation instructions for PyTPG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import random\n",
    "\n",
    "# how to render in Jupyter: \n",
    "# https://stackoverflow.com/questions/40195740/how-to-run-openai-gym-render-over-a-server\n",
    "# https://www.youtube.com/watch?v=O84KgRt6AJI\n",
    "def show_state(env, step=0, name='', info=''):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (name, step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "# To transform pixel matrix to a single vector.\n",
    "def getState(inState):\n",
    "    # each row is all 1 color\n",
    "    rgbRows = np.reshape(inState,(len(inState[0])*len(inState), 3)).T\n",
    "\n",
    "    # add each with appropriate shifting\n",
    "    # get RRRRRRRR GGGGGGGG BBBBBBBB\n",
    "    return np.add(np.left_shift(rgbRows[0], 16),\n",
    "        np.add(np.left_shift(rgbRows[1], 8), rgbRows[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Assault-v0') # make the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # learn size of action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to do training\n",
    "from tpg.trainer import Trainer\n",
    "# import to run an agent (always needed)\n",
    "from tpg.agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Basic Generational Selection (with graphics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken (Hours): 0.5528749724229177\n",
      "Results:\n",
      "Min, Max, Avg\n",
      "0.0 273.0 26.25\n",
      "0.0 273.0 22.0\n",
      "0.0 231.0 30.45\n",
      "0.0 273.0 50.4\n",
      "0.0 294.0 131.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import time # for tracking time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "# first create an instance of the TpgTrainer\n",
    "# this creates the whole population and everything\n",
    "# teamPopSize should realistically be at-least 100\n",
    "trainer = Trainer(actions=range(7), teamPopSize=20, rTeamPopSize=20) \n",
    "\n",
    "curScores = [] # hold scores in a generation\n",
    "summaryScores = [] # record score summaries for each gen (min, max, avg)\n",
    "\n",
    "# 5 generations isn't much (not even close), but some improvements\n",
    "# should be seen.\n",
    "for gen in range(5): # generation loop\n",
    "    curScores = [] # new list per gen\n",
    "    \n",
    "    agents = trainer.getAgents()\n",
    "    \n",
    "    while True: # loop to go through agents\n",
    "        teamNum = len(agents)\n",
    "        agent = agents.pop()\n",
    "        if agent is None:\n",
    "            break # no more agents, so proceed to next gen\n",
    "        \n",
    "        state = env.reset() # get initial state and prep environment\n",
    "        score = 0\n",
    "        for i in range(500): # run episodes that last 500 frames\n",
    "            show_state(env, i, 'Assault', 'Gen #' + str(gen) + \n",
    "                       ', Team #' + str(teamNum) +\n",
    "                       ', Score: ' + str(score)) # render env\n",
    "            \n",
    "            # get action from agent\n",
    "            # must transform to at-least int-32 (for my getState to bitshift correctly)\n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32))) \n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            score += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "\n",
    "        agent.reward(score) # must reward agent (if didn't already score)\n",
    "            \n",
    "        curScores.append(score) # store score\n",
    "        \n",
    "        if len(agents) == 0:\n",
    "            break\n",
    "            \n",
    "    # at end of generation, make summary of scores\n",
    "    summaryScores.append((min(curScores), max(curScores),\n",
    "                    sum(curScores)/len(curScores))) # min, max, avg\n",
    "    trainer.evolve()\n",
    "    \n",
    "#clear_output(wait=True)\n",
    "print('Time Taken (Hours): ' + str((time.time() - tStart)/3600))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for result in summaryScores:\n",
    "    print(result[0],result[1],result[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Generational Selection with Multiprocessing (no graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is just to show a different way to run the API, a far superior way. It uses a different method to get the agents, doesn't use graphics (but can), and uses multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run each agent in this method for parallization.\n",
    "Args:\n",
    "    args: (TpgAgent, envName, scoreList, numEpisodes, numFrames)\n",
    "\"\"\"\n",
    "def runAgent(args):\n",
    "    agent = args[0]\n",
    "    envName = args[1]\n",
    "    scoreList = args[2]\n",
    "    numEpisodes = args[3] # number of times to repeat game\n",
    "    numFrames = args[4] \n",
    "    \n",
    "    # skip if task already done by agent\n",
    "    if agent.taskDone(envName):\n",
    "        print('Agent #' + str(agent.agentNum) + ' can skip.')\n",
    "        scoreList.append((agent.team.id, agent.team.outcomes))\n",
    "        return\n",
    "    \n",
    "    env = gym.make(envName)\n",
    "    valActs = range(env.action_space.n) # valid actions, some envs are less\n",
    "    \n",
    "    scoreTotal = 0 # score accumulates over all episodes\n",
    "    for ep in range(numEpisodes): # episode loop\n",
    "        state = env.reset()\n",
    "        scoreEp = 0\n",
    "        numRandFrames = 0\n",
    "        if numEpisodes > 1:\n",
    "            numRandFrames = random.randint(0,30)\n",
    "        for i in range(numFrames): # frame loop\n",
    "            if i < numRandFrames:\n",
    "                env.step(env.action_space.sample())\n",
    "                continue\n",
    "\n",
    "            act = agent.act(getState(np.array(state, dtype=np.int32)))\n",
    "\n",
    "            # feedback from env\n",
    "            state, reward, isDone, debug = env.step(act)\n",
    "            scoreEp += reward # accumulate reward in score\n",
    "            if isDone:\n",
    "                break # end early if losing state\n",
    "                \n",
    "        print('Agent #' + str(agent.agentNum) + \n",
    "              ' | Ep #' + str(ep) + ' | Score: ' + str(scoreEp))\n",
    "        scoreTotal += scoreEp\n",
    "       \n",
    "    scoreTotal /= numEpisodes\n",
    "    env.close()\n",
    "    agent.reward(scoreTotal, envName)\n",
    "    scoreList.append((agent.team.id, agent.team.outcomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken (Hours): 0.6682543623447418\n",
      "Results:\n",
      "Min, Max, Avg\n",
      "-100.0 2.0 -47.45\n",
      "-100.0 6.0 -35.53611111111111\n",
      "-100.0 6.0 -31.63888888888889\n",
      "-100.0 6.0 -28.647222222222222\n",
      "-100.0 6.0 -28.208333333333332\n",
      "-100.0 6.0 -26.36111111111111\n",
      "-100.0 14.0 -24.522222222222222\n",
      "-100.0 14.0 -21.580555555555556\n",
      "-100.0 14.0 -21.383333333333333\n",
      "-100.0 30.0 -17.294444444444444\n",
      "-100.0 30.0 -17.705555555555556\n",
      "-100.0 30.0 -14.257617728531857\n",
      "-100.0 33.0 -12.18836565096953\n",
      "-100.0 33.0 -15.669444444444444\n",
      "-100.0 33.0 -13.061111111111112\n",
      "-100.0 33.0 -13.466666666666667\n",
      "-100.0 33.0 -11.46111111111111\n",
      "-100.0 33.0 -15.505555555555556\n",
      "-100.0 33.0 -11.063888888888888\n",
      "-100.0 33.0 -11.941666666666666\n",
      "-100.0 33.0 -10.272222222222222\n",
      "-100.0 33.0 -9.730555555555556\n",
      "-100.0 33.0 -10.994459833795014\n",
      "-100.0 33.0 -8.329639889196676\n",
      "-100.0 33.0 -9.218836565096954\n",
      "-100.0 33.0 -10.191135734072022\n",
      "-100.0 33.0 -6.423822714681441\n",
      "-100.0 37.0 -11.9196675900277\n",
      "-100.0 37.0 -9.066481994459833\n",
      "-100.0 37.0 -8.366666666666667\n",
      "-100.0 37.0 -9.394444444444444\n",
      "-100.0 37.0 -6.913888888888889\n",
      "-100.0 37.0 -9.333333333333334\n",
      "-100.0 37.0 -5.030555555555556\n",
      "-100.0 37.0 -8.759002770083102\n",
      "-100.0 37.0 -7.997222222222222\n",
      "-100.0 37.0 -6.275\n",
      "-100.0 37.0 -6.902777777777778\n",
      "-100.0 37.0 -11.38888888888889\n",
      "-100.0 37.0 -4.730555555555555\n",
      "-100.0 43.0 -4.8448753462603875\n",
      "-100.0 43.0 -7.119113573407202\n",
      "-100.0 43.0 -5.0777777777777775\n",
      "-100.0 43.0 -5.2555555555555555\n",
      "-100.0 45.0 -11.594444444444445\n",
      "-100.0 45.0 -4.905555555555556\n",
      "-100.0 45.0 -7.513888888888889\n",
      "-100.0 45.0 -11.622222222222222\n",
      "-100.0 45.0 -1.8\n",
      "-100.0 45.0 -5.822222222222222\n",
      "-100.0 45.0 -3.852777777777778\n",
      "-100.0 45.0 -6.8310249307479225\n",
      "-100.0 45.0 -7.388888888888889\n",
      "-100.0 45.0 -1.875\n",
      "-100.0 45.0 -4.3694444444444445\n",
      "-100.0 45.0 -7.25\n",
      "-100.0 45.0 -3.1333333333333333\n",
      "-100.0 45.0 -8.20775623268698\n",
      "-100.0 45.0 0.058333333333333334\n",
      "-100.0 45.0 -5.655555555555556\n",
      "-100.0 45.0 -1.4376731301939059\n",
      "-100.0 45.0 -1.8166666666666667\n",
      "-100.0 45.0 -5.725\n",
      "-100.0 45.0 -4.950138504155125\n",
      "-100.0 45.0 -3.316666666666667\n",
      "-100.0 45.0 -5.166666666666667\n",
      "-100.0 45.0 -5.772222222222222\n",
      "-100.0 45.0 -1.6277777777777778\n",
      "-100.0 45.0 -4.1551246537396125\n",
      "-100.0 45.0 -6.052777777777778\n",
      "-100.0 45.0 -1.0833333333333333\n",
      "-100.0 45.0 1.8833333333333333\n",
      "-100.0 45.0 -7.427777777777778\n",
      "-100.0 45.0 -5.441666666666666\n",
      "-100.0 45.0 -7.833333333333333\n",
      "-100.0 45.0 -2.9002770083102494\n",
      "-100.0 45.0 -2.7055555555555557\n",
      "-100.0 45.0 1.3822714681440442\n",
      "-100.0 45.0 -2.3102493074792245\n",
      "-100.0 53.0 -2.1662049861495847\n",
      "-100.0 53.0 -0.8614958448753463\n",
      "-100.0 53.0 -4.366666666666666\n",
      "-100.0 53.0 -7.602777777777778\n",
      "-100.0 53.0 3.4055555555555554\n",
      "-100.0 53.0 -6.336111111111111\n",
      "-100.0 53.0 -3.027700831024931\n",
      "-100.0 53.0 -0.8836565096952909\n",
      "-100.0 53.0 -2.011111111111111\n",
      "-100.0 53.0 -1.5833333333333333\n",
      "-100.0 53.0 -3.4444444444444446\n",
      "-100.0 53.0 -4.308333333333334\n",
      "-100.0 53.0 -2.1166666666666667\n",
      "-100.0 53.0 -1.2416666666666667\n",
      "-100.0 53.0 -0.5472222222222223\n",
      "-100.0 53.0 -2.1333333333333333\n",
      "-100.0 53.0 -1.5416666666666667\n",
      "-100.0 53.0 -1.0387811634349031\n",
      "-100.0 53.0 -3.8944444444444444\n",
      "-100.0 53.0 -0.625\n",
      "-100.0 53.0 1.3490304709141274\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "tStart = time.time()\n",
    "\n",
    "envName = 'Boxing-v0'\n",
    "# get num actions\n",
    "env = gym.make(envName)\n",
    "acts = env.action_space.n\n",
    "del env\n",
    "\n",
    "trainer = Trainer(actions=range(acts), teamPopSize=360, rTeamPopSize=360)\n",
    "\n",
    "processes = 23\n",
    "man = mp.Manager()\n",
    "pool = mp.Pool(processes=processes, maxtasksperchild=1)\n",
    "    \n",
    "allScores = [] # track all scores each generation\n",
    "\n",
    "for gen in range(100): # do 100 generations of training\n",
    "    scoreList = man.list()\n",
    "    \n",
    "    # get agents, noRef to not hold reference to trainer in each one\n",
    "    # don't need reference to trainer in multiprocessing\n",
    "    agents = trainer.getAgents() # swap out agents only at start of generation\n",
    "\n",
    "    # run the agents\n",
    "    pool.map(runAgent, \n",
    "        [(agent, envName, scoreList, 1, 18000)\n",
    "        for agent in agents])\n",
    "    \n",
    "    # apply scores, must do this when multiprocessing\n",
    "    # because agents can't refer to trainer\n",
    "    teams = trainer.applyScores(scoreList)\n",
    "    # important to remember to set tasks right, unless not using task names\n",
    "    # task name set in runAgent()\n",
    "    trainer.evolve(tasks=[envName]) # go into next gen\n",
    "    \n",
    "    # an easier way to track stats than the above example\n",
    "    scoreStats = trainer.fitnessStats\n",
    "    allScores.append((scoreStats['min'], scoreStats['max'], scoreStats['average']))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Time Taken (Hours): ' + str((time.time() - tStart)/3600))\n",
    "    print('Gen: ' + str(gen))\n",
    "    print('Results so far: ' + str(allScores))\n",
    "    \n",
    "clear_output()\n",
    "print('Time Taken (Hours): ' + str((time.time() - tStart)/3600))\n",
    "print('Results:\\nMin, Max, Avg')\n",
    "for score in allScores:\n",
    "    print(score[0],score[1],score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oaigym]",
   "language": "python",
   "name": "conda-env-oaigym-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
